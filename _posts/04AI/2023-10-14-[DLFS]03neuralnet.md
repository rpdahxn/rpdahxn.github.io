---
title: "[밑시딥] 3장 신경망"
categories:
  - AI
toc: true
toc_sticky: true
toc_icon: "sticky-note"
use_math: true
comments: true
---
`DeepLearningFromScratch CHAPTER3 Neural Network`
<br/>
 
# 퍼셉트론에서 신경망으로
앞 장에서 퍼셉트론으로 복잡한 함수도 표현할 수 있다고 했지만 원하는 결과가 출력되도록 적절한 가중치 값을 설정하는 작업은 여전히 사람이 **수동으로** 해줘야 한다.     
이 문제를 신경망이 해결해 준다.       
신경망은 가중치 매개변수의 적절한 값을 데이터로부터 **자동으로 학습**한다.     
퍼셉트론에서 신경망으로 나아가면서 **활성화 함수***activation function* 개념이 등장한다.      
<br/>

# 활성화 함수
활성화 함수란 입력 신호의 총합을 출력 신호로 변환하는 함수를 가리키며 그 종류는 다양하다.       
일반적으로 **단층** 네트워크에서 **계단 함수**를 활성화 함수로 사용한 모델을 **단순 퍼셉트론**이라 한다.     
**여러 층**으로 구성되고 시그모이드 함수 등의 **매끈한 활성화 함수**를 사용하는 네트워크를 **신경망**(다층 퍼셉트론)이라 한다.      
    
활성화 함수로 시그모이드 함수, 계단 함수, ReLU함수 등이 있다.    
시그모이드 함수와 계단 함수는 입력이 중요할수록 큰 값을 출력하며 그 값은 0에서 1사이에서만 존재한다.      
ReLU는 입력이 0을 넘으면 그 값을 그대로 출력하고, 0이하이면 0을 출력한다.     
<br/>

# 왜 비선형 함수?
신경망에서는 활성화 함수로 선형 함수가 아닌 비선형 함수를 사용해야 한다.     
**선형 함수를 사용하면 신경망의 층을 깊게 하는 것의 의미가 없어진다.**     
선형 함수를 사용할 경우 신경망을 여러 층으로 구성하는 이점을 살릴 수 없다.     
<br/>

| 🙊 잘 몰랐던 개념; *3x2 행렬이란 처음 *차원에는 원소가 3개, 다음 *차원에는 원소가 2개 있다는 의미이다.*
<br/>

# 다차원 배열의 계산
넘파이의 다차원 배열을 통해 신경망을 효율적으로 구현할 수 있다.    
행렬곱 연산을 이용한다.      
<br/>

# 분류 / 회귀 문제
어떤 문제냐에 따라 신경망의 출력층에서 사용하는 활성화 함수가 달라진다.    
일반적으로 회귀에는 항등 함수를, 분류에는 소프트맥스 함수를 사용한다.    

**항등 함수***identity function*      
입력을 그대로 출력한다.     

**소프트맥스 함수***softmax function*      
$$y_k = \frac{exp(a_k)}{\sum_{i=1}^{n}exp(a_i)}$$     
소프트맥스 함수의 출력은 **'확률'**로 해석할 수 있다.     
<br/>

# 배치 처리
입력 데이터를 묶은 것을 가리킨다. 배치 단위로 추론을 진행하면 결과를 훨씬 빠르게 얻을 수 있다.
<br/>

# Reference
📖 [밑바닥부터 시작하는 딥러닝 ](https://product.kyobobook.co.kr/detail/S000001057805)